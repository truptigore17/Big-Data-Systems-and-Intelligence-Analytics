{"cells":[{"cell_type":"code","source":["#Part 1, 2 and 3 of Assignment"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["spark"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["#Read file from csv in the Table\ndf = spark.read.csv(\"/FileStore/tables/CleanedLoanData.csv\",\n                      inferSchema=\"true\", header=\"true\")"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["#Check for datatype for anamalies\ndf.dtypes"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["#check the table \ndisplay(df.select('*'))"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["#Q1 : What are the different type of grades a person can have?\ndf.select('grade').distinct().show()"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["#Q2 : How many count of grades?\ndisplay(df.select('grade').groupBy('grade').count().orderBy(\"count\", ascending = False))"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["#Q3 : Find interest rate of each issue year\ndisplay(df.select('issue_year','int_rate').groupBy('issue_year').max(\"int_rate\"). orderBy(\"issue_year\", ascending = True))"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["#Q4 : What is the total current balance for each of the purpose of taking loans ?\ndisplay(df.select(\"purpose\", 'tot_cur_bal').groupBy('purpose').sum(\"tot_cur_bal\"). orderBy(\"purpose\"))"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["#Q5 : What is the highest annual income of the customer who lent money for each termtotal current balance for each of the purpose of taking loans ?\ndisplay(df.select(\"term\", 'annual_inc').groupBy('term').max(\"annual_inc\"))"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["#Q6 what is the average annual income of people from each address code?\ndisplay(df.select(\"addr_state\", 'annual_inc').groupBy('addr_state').avg(\"annual_inc\"))"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["#Q7 what is the count of applicants with purpose?\ndisplay(df.select('purpose').groupBy('purpose').count().orderBy(\"count\", ascending = True))"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["#Q8 What is the minimum loan amount for each each loan status?\ndisplay(df.select(\"loan_status\", 'loan_amnt').groupBy('loan_status').min(\"loan_amnt\"))"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["#Q9 what is the average risk score for Direct payment?\ndisplay(df.select(\"disbursement_method\", 'Risk_Score').groupBy('disbursement_method').avg(\"Risk_Score\"))"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["#Q10 When was the lowest interest rate for each year?\ndisplay(df.select(\"int_rate\", \"issue_year\").groupBy('issue_year').min(\"int_rate\"))"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["#Use features for the project drilled down by feature engineering\nmodel_data = df.select('loan_amnt','term', 'emp_length', 'home_ownership', 'annual_inc','verification_status','delinq_2yrs','Risk_Score','inq_last_6mths','open_acc','revol_bal','revol_util','total_acc','mths_since_last_major_derog','funded_amnt_inv','installment','pub_rec','dti','addr_state', 'int_rate')\n#Divide data in test and train with random split of 90-10 train to test\ntrain, test = model_data.randomSplit([0.9, 0.1], seed=12345)"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["#View how train data looks\ndisplay(train)"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["from pyspark.ml.feature import VectorAssembler, VectorIndexer\nfeaturesCols = model_data.columns\n\n# This concatenates all feature columns into a single feature vector in a new column \"rawFeatures\".\nvectorAssembler = VectorAssembler(inputCols=featuresCols, outputCol=\"rawFeatures\")\n# This identifies categorical features and indexes them.\nvectorIndexer = VectorIndexer(inputCol=\"rawFeatures\", outputCol=\"features\")\n"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["from pyspark.ml.regression import GBTRegressor\n# Takes the \"features\" column and learns to predict \"cnt\"\ngbt_reg = GBTRegressor(labelCol=\"int_rate\")"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\nfrom pyspark.ml.evaluation import RegressionEvaluator\n# Define a grid of hyperparameters to test:\n#  - maxDepth: max depth of each decision tree in the GBT ensemble\n#  - maxIter: iterations, i.e., number of trees in each GBT ensemble\n# In this example notebook, we keep these values small.  In practice, to get the highest accuracy, you would likely want to try deeper trees (10 or higher) and more trees in the ensemble (>100).\nparamGrid = ParamGridBuilder()\\\n  .addGrid(gbt_reg.maxDepth, [2, 5])\\\n  .addGrid(gbt_reg.maxIter, [10, 100])\\\n  .build()\n# We define an evaluation metric.  This tells CrossValidator how well we are doing by comparing the true labels with predictions.\nevaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=gbt_reg.getLabelCol(), predictionCol=gbt_reg.getPredictionCol())\n# Declare the CrossValidator, which runs model tuning for us.\ncv = CrossValidator(estimator=gbt_reg, evaluator=evaluator, estimatorParamMaps=paramGrid)"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["#Put pipeline\nfrom pyspark.ml import Pipeline\npipeline = Pipeline(stages=[vectorAssembler, vectorIndexer, cv])"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":["#Train model\npipelineModel = pipeline.fit(train)"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":["#Predict data on test\npredictions = pipelineModel.transform(test)"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["#View the predictions\ndisplay(predictions.select(\"int_rate\", \"prediction\", *featuresCols))"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":["#Check accuracy\nrmse = evaluator.evaluate(predictions)\nprint \"RMSE on our test set: %g\" % rmse"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"code","source":["#View Output\ndisplay(predictions.select(\"loan_amnt\", \"prediction\"))"],"metadata":{},"outputs":[],"execution_count":26}],"metadata":{"name":"Project_Spark Assignment","notebookId":3072046661827866},"nbformat":4,"nbformat_minor":0}
